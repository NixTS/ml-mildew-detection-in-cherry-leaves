{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PP5 - Powdery Mildew Detection in Cherry Leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3 - Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "\n",
    "* Awnser business requirement No. 2\n",
    "    * The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew.\n",
    " \n",
    "**Inputs**\n",
    "\n",
    "Images from the following folders\n",
    "\n",
    "```\n",
    ".\n",
    "└── input/\n",
    "    ├── test/\n",
    "    │   ├── healthy\n",
    "    │   └── mildew\n",
    "    ├── train/\n",
    "    │   ├── healthy\n",
    "    │   └── mildew\n",
    "    └── validation/\n",
    "        ├── healthy\n",
    "        └── mildew\n",
    "```\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* Analysis of Data Distribution across Sets (train, validation and test) and Labels (healthy and mildew)\n",
    "    * Label distribution table, saved as: .png\n",
    "    * Label distribution as a bar chart, saved as: .png\n",
    "    * Set distribution as a pie chart, saved as: .png\n",
    "* Image augmentation, each set is augmented and plotted\n",
    "* Class indices to change prediction inference in labels, saved as pickle file: class_indices.pkl\n",
    "* Machine learning model and model summary\n",
    "* Model training\n",
    "* Model saved as keras file: mildew_detector_model.keras\n",
    "* Learning curve plot for model performance \n",
    "    * Loss, saved as: .png\n",
    "    * Accuracy saved as: .png\n",
    "* Model evaluation and saved as pickle file: evaluation.pkl\n",
    "* Confusion matrix, saved as: .png\n",
    "* Classification report, saved as: .png\n",
    "* Prediction on random image files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace/ml-mildew-detection-in-cherry-leaves')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "working_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Input Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir= 'input/cherry-leaves'\n",
    "train_path = dataset_dir + '/train'\n",
    "val_path = dataset_dir + '/validation'\n",
    "test_path = dataset_dir + '/test'\n",
    "print(f\"Train Set Path: {train_path}\")\n",
    "print(f\"Validation Set Path: {val_path}\")\n",
    "print(f\"Test Set Path: {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Output Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(working_dir) and version in os.listdir(working_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)\n",
    "\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Label Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Image shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = joblib.load(filename=f'outputs/{version}/avg_image_shape_train.pkl')\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Data Distribution across Sets and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data_distribution(dataset_dir, file_path):\n",
    "    '''\n",
    "    Display the distribution of data across different sets and labels.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir (str): The directory containing the datasets.\n",
    "        file_path (str): The directory where the output images will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    data = []\n",
    "    for folder in ['test', 'train', 'validation']:\n",
    "        folder_path = os.path.join(dataset_dir, folder)\n",
    "        for label in os.listdir(folder_path):\n",
    "            label_path = os.path.join(folder_path, label)\n",
    "            frequency = len(os.listdir(label_path))\n",
    "            data.append({'Set': folder, 'Label': label, 'Frequency': frequency})\n",
    "\n",
    "    df_freq = pd.DataFrame(data)\n",
    "\n",
    "    custom_palette = sns.color_palette(\"magma\", len(df_freq['Label'].unique()))\n",
    "\n",
    "    # Display numerical data\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.axis('off')\n",
    "    table = plt.table(cellText=df_freq.values,\n",
    "                      colLabels=df_freq.columns,\n",
    "                      cellLoc='left',\n",
    "                      loc='center')\n",
    "    table.set_fontsize(10)\n",
    "    for key, cell in table.get_celld().items():\n",
    "        cell.set_linestyle('-')\n",
    "        cell.set_edgecolor('lightgray')\n",
    "    plt.savefig(os.path.join(file_path, 'labels_distribution_table.png'), bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the bar plot\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label', palette=custom_palette)\n",
    "    plt.title('Distribution of Labels in Different Sets', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Set', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.savefig(os.path.join(file_path, 'labels_distribution_bar.png'), bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the pie chart\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.pie(df_freq.groupby('Label')['Frequency'].sum(), labels=None,\n",
    "            autopct='%1.1f%%', startangle=140, colors=custom_palette)\n",
    "    plt.title('Total Data in Each Label', fontsize=16, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.legend(df_freq['Label'].unique(), fontsize=12, loc='lower right')\n",
    "    plt.savefig(os.path.join(file_path, 'labels_pie_chart.png'), bbox_inches='tight', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data_distribution(dataset_dir, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_data = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    fill_mode='nearest',\n",
    "    rescale=1.0/255.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation Train image Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = augmentation_data.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_shape[:2],\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation Validation image Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = augmentation_data.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=image_shape[:2],\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation Test image Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = augmentation_data.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=image_shape[:2],\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Augmented Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {i: label for i, label in enumerate(labels)}\n",
    "print('Label names:', label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmented Train Image Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "\n",
    "for i in range(9):\n",
    "    img, label = next(train_set)\n",
    "    label_name = label_names[label[0]]\n",
    "    \n",
    "    axes[i // 3, i % 3].imshow(img[0])\n",
    "    axes[i // 3, i % 3].set_title(label_name)\n",
    "    \n",
    "    axes[i // 3, i % 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmented Validation Image Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "\n",
    "for i in range(9):\n",
    "    img, label = next(validation_set)\n",
    "    label_name = label_names[label[0]]\n",
    "    \n",
    "    axes[i // 3, i % 3].imshow(img[0])\n",
    "    axes[i // 3, i % 3].set_title(label_name)\n",
    "    \n",
    "    axes[i // 3, i % 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmented Test Image Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "\n",
    "for i in range(9):\n",
    "    img, label = next(test_set)\n",
    "    label_name = label_names[label[0]]\n",
    "    \n",
    "    axes[i // 3, i % 3].imshow(img[0])\n",
    "    axes[i // 3, i % 3].set_title(label_name)\n",
    "    \n",
    "    axes[i // 3, i % 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save class_indicies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Model Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Builds a convolutional neural network (CNN) model\n",
    "\n",
    "    Parameters:\n",
    "        image_shape - tuple: The shape of input images (height, width, channels)\n",
    "\n",
    "    Returns:\n",
    "        model - Sequential: A TensorFlow Keras Sequential model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    model.add(Conv2D(filters=16,\n",
    "                     kernel_size=(3, 3),\n",
    "                     input_shape=image_shape,\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Convolutional Layers\n",
    "    model.add(Conv2D(filters=32,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          validation_data=validation_set,\n",
    "          callbacks=[early_stop],\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'outputs/{version}/mildew_detector_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Learning Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[['loss', 'val_loss']].plot(style='.-', cmap='viridis')\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.savefig(f'{file_path}/model_loss_training.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[['accuracy', 'val_accuracy']].plot(style='.-', cmap='viridis')\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.savefig(f'{file_path}/model_accuracy_training.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss and Accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    loaded_model = load_model(f'outputs/{version}/mildew_detector_model.keras')\n",
    "    print(f\"Model {version} loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading model:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Accuracy: {evaluation[1] * 100:.2f}%\")\n",
    "print(f\"Loss: {evaluation[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f\"outputs/{version}/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pred = model.predict(test_set)\n",
    "y_pred = np.concatenate(np.round(pred).astype(int))\n",
    "target_names = labels\n",
    "\n",
    "cm = confusion_matrix(test_set.classes, y_pred)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            cmap='magma',\n",
    "            xticklabels=['Healthy', 'Mildew'],\n",
    "            yticklabels=['Healthy', 'Mildew'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.savefig(f'{file_path}/confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
    "\n",
    "clf = classification_report(test_set.classes, y_pred, target_names=target_names, output_dict=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(pd.DataFrame(clf).iloc[:-1, :].T, annot=True, cmap=\"magma\", cbar=False, linewidths=1)\n",
    "plt.title('Classification Report')\n",
    "\n",
    "plt.savefig(f'{file_path}/classification_report.png', bbox_inches='tight', dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "pointer = 30\n",
    "label = labels[0]\n",
    "\n",
    "image_path = os.path.join(\n",
    "    test_path, label, os.listdir(os.path.join(test_path, label))[pointer])\n",
    "\n",
    "pil_image = image.load_img(image_path,\n",
    "                           target_size=image_shape, color_mode='rgb')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)/255\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0, 0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class = target_map[pred_proba > 0.5]\n",
    "\n",
    "if pred_class == target_map[0]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
